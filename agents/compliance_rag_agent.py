"""
Agente 1: Chatbot de Consulta de Compliance (RAG)

Este agente √© respons√°vel por responder perguntas sobre as regras de compliance
usando Retrieval-Augmented Generation (RAG) com ChromaDB.

Arquitetura:
- Vector Store: ChromaDB
- Embeddings: ChromaDB default (all-MiniLM-L6-v2)
- LLM: Groq (Llama 3.1 70B ou modelo configurado)
- Retrieval: Top-k similarity search
"""

import chromadb
from chromadb.config import Settings
from typing import List, Dict
import config
from utils.document_loader import load_compliance_policy, split_text_for_rag
from utils.llm_adapter import LLMAdapter


class ComplianceRAGAgent:
    """
    Agente de RAG para consultas sobre pol√≠tica de compliance
    Compat√≠vel com m√∫ltiplos provedores de LLM via LLMAdapter
    """
    
    def __init__(self):
        # Usar adaptador universal de LLM
        self.llm = LLMAdapter()
        
        # Inicializar ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path=str(config.CHROMA_PERSIST_DIR)
        )
        
        # Tentar obter cole√ß√£o existente ou criar nova
        try:
            self.collection = self.chroma_client.get_collection(
                name=config.COLLECTION_NAME
            )
            print("‚úì Cole√ß√£o ChromaDB carregada")
        except:
            print("Criando nova cole√ß√£o ChromaDB...")
            self._initialize_vector_store()
    
    def _initialize_vector_store(self):
        """Inicializa o vector store com a pol√≠tica de compliance"""
        # Carregar pol√≠tica
        policy_text = load_compliance_policy(str(config.COMPLIANCE_POLICY_PATH))
        
        # Dividir em chunks
        chunks = split_text_for_rag(policy_text, chunk_size=800, chunk_overlap=150)
        
        # Criar cole√ß√£o
        # ChromaDB usa embeddings padr√£o (all-MiniLM-L6-v2) automaticamente
        self.collection = self.chroma_client.create_collection(
            name=config.COLLECTION_NAME,
            metadata={"description": "Dunder Mifflin Compliance Policy"}
        )
        
        # Adicionar chunks ao vector store
        for i, chunk in enumerate(chunks):
            self.collection.add(
                documents=[chunk],
                ids=[f"chunk_{i}"],
                metadatas=[{"chunk_id": i, "source": "politica_compliance.txt"}]
            )
        
        print(f"‚úì Vector store inicializado com {len(chunks)} chunks")
    
    def _retrieve_relevant_chunks(self, query: str, n_results: int = 4) -> List[str]:
        """
        Recupera chunks relevantes para a query
        
        Args:
            query: Pergunta do usu√°rio
            n_results: N√∫mero de chunks a retornar (padr√£o: 4)
            
        Returns:
            Lista de chunks relevantes
        """
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )
        
        return results['documents'][0] if results['documents'] else []
    
    def query(self, user_question: str) -> str:
        """
        Responde pergunta do usu√°rio usando RAG
        
        Args:
            user_question: Pergunta do funcion√°rio
            
        Returns:
            Resposta fundamentada na pol√≠tica de compliance
        """
        # Recuperar chunks relevantes
        relevant_chunks = self._retrieve_relevant_chunks(user_question, n_results=4)
        
        if not relevant_chunks:
            return "Desculpe, n√£o encontrei informa√ß√µes relevantes na pol√≠tica de compliance para responder sua pergunta."
        
        # Construir contexto
        context = "\n\n---\n\n".join(relevant_chunks)
        
        # System prompt otimizado para Groq/Llama
        system_prompt = """Voc√™ √© um assistente especializado em compliance da Dunder Mifflin.
Sua fun√ß√£o √© ajudar funcion√°rios a entender e seguir as pol√≠ticas de compliance da empresa.

REGRAS IMPORTANTES:
1. Responda APENAS com base no contexto fornecido da pol√≠tica de compliance
2. Se a informa√ß√£o n√£o estiver no contexto, diga explicitamente que n√£o encontrou
3. Seja preciso e cite se√ß√µes espec√≠ficas quando relevante (ex: "De acordo com a Se√ß√£o 1.1...")
4. Use um tom profissional mas acess√≠vel e direto
5. Se houver valores monet√°rios ou prazos, cite-os exatamente como aparecem na pol√≠tica
6. Sempre que poss√≠vel, explique PORQU√ä a regra existe (contexto/motiva√ß√£o)
7. Seja conciso mas completo - n√£o invente informa√ß√µes al√©m do contexto fornecido"""

        user_prompt = f"""CONTEXTO DA POL√çTICA DE COMPLIANCE:
{context}

PERGUNTA DO FUNCION√ÅRIO:
{user_question}

Por favor, responda √† pergunta com base apenas nas informa√ß√µes do contexto acima. Seja direto e preciso."""

        # Usar adaptador LLM (funciona com Groq)
        answer = self.llm.generate(
            system_prompt=system_prompt,
            user_prompt=user_prompt
        )
        
        return answer
    
    def reset_vector_store(self):
        """Reseta o vector store (√∫til para testes)"""
        try:
            self.chroma_client.delete_collection(name=config.COLLECTION_NAME)
            print("‚úì Vector store resetado")
        except:
            print("Nenhum vector store para resetar")


def main():
    """Teste interativo do agente"""
    print("=" * 80)
    print("AGENTE 1: CHATBOT DE CONSULTA DE COMPLIANCE")
    print("=" * 80)
    print()
    
    # Mostrar configura√ß√£o do LLM
    config.print_config_info()
    
    agent = ComplianceRAGAgent()
    
    # Perguntas de teste
    test_questions = [
        "Qual √© o limite de gastos que posso fazer sem aprova√ß√£o?",
        "Posso comprar equipamento de karaok√™ para uma apresenta√ß√£o de vendas?",
        "Quem aprova despesas entre $50 e $500?",
        "Posso dividir uma compra de $800 em duas notas fiscais de $400?",
        "Posso ser reembolsado por um jantar no Hooters com um cliente?"
    ]
    
    print("\n" + "="*80)
    print("TESTES AUTOM√ÅTICOS")
    print("="*80)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*80}")
        print(f"TESTE {i}: {question}")
        print(f"{'='*80}")
        
        import time
        start_time = time.time()
        answer = agent.query(question)
        elapsed = time.time() - start_time
        
        print(f"\nRESPOSTA:\n{answer}")
        print(f"\n‚è±Ô∏è  Tempo: {elapsed:.2f}s")
    
    # Modo interativo
    print("\n" + "="*80)
    print("MODO INTERATIVO (digite 'sair' para encerrar)")
    print("="*80)
    
    while True:
        question = input("\nüìã Sua pergunta: ").strip()
        if question.lower() in ['sair', 'exit', 'quit', 'voltar']:
            break
        if question:
            import time
            start_time = time.time()
            answer = agent.query(question)
            elapsed = time.time() - start_time
            
            print(f"\nüí° Resposta: {answer}")
            print(f"‚è±Ô∏è  Tempo: {elapsed:.2f}s\n")
            print("-" * 80)


if __name__ == "__main__":
    main()